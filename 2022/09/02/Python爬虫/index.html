<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Python spider | Qué miras Bobo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="反爬虫策略 设置合理的请求头。   123headers &#x3D; &#123;   # 伪装浏览器请求头   &#x27;Cookie&#x27;: &#x27;ispeed_lsm&#x3D;2; baikeVisitId&#x3D;b84d4a50-436c-4e0f-9e29-dc2393e9cdca; COOKIE_SESSION&#x3D;6_1_8_5_10_9_1_0_7_5_0_3_33002_0_2_0_1650">
<meta property="og:type" content="article">
<meta property="og:title" content="Python spider">
<meta property="og:url" content="http://example.com/2022/09/02/Python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Qué miras Bobo">
<meta property="og:description" content="反爬虫策略 设置合理的请求头。   123headers &#x3D; &#123;   # 伪装浏览器请求头   &#x27;Cookie&#x27;: &#x27;ispeed_lsm&#x3D;2; baikeVisitId&#x3D;b84d4a50-436c-4e0f-9e29-dc2393e9cdca; COOKIE_SESSION&#x3D;6_1_8_5_10_9_1_0_7_5_0_3_33002_0_2_0_1650">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-09-02T03:11:00.000Z">
<meta property="article:modified_time" content="2023-10-31T12:34:19.564Z">
<meta property="article:author" content="fengcai">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Qué miras Bobo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="https://github.com/leo710aka/bk/blob/main/DT1.jpg?raw=true">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Qué miras Bobo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Python爬虫" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/09/02/Python%E7%88%AC%E8%99%AB/" class="article-date">
  <time class="dt-published" datetime="2022-09-02T03:11:00.000Z" itemprop="datePublished">2022-09-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Python spider
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="反爬虫策略"><a href="#反爬虫策略" class="headerlink" title="反爬虫策略"></a><strong>反爬虫策略</strong></h3><ul>
<li>设置合理的请求头。   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;   <span class="comment"># 伪装浏览器请求头</span></span><br><span class="line">   <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;ispeed_lsm=2; baikeVisitId=b84d4a50-436c-4e0f-9e29-dc2393e9cdca; COOKIE_SESSION=6_1_8_5_10_9_1_0_7_5_0_3_33002_0_2_0_1650022038_1650022034_1650022036%7C8%230_1_1650022030%7C1; BD_UPN=1126314751; BD_HOME=1; BD_CK_SAM=1; H_PS_645EC=89b2Pt9WoxiJHIC80g9QL3FIo7tdoc9Z9Gm9Nd6gkOPipOmTDtckrFlLxEpchFYkItCM; BAIDUID=FD56AC9125756B81A0E4EB7A60F27700:FG=1; BIDUPSID=FD56AC9125756B81E8CE802CC99B8074; PSTM=1648004100; BDUSS=Jpc2d4NGIwdzRCNVFTR0xNeS1IYXBLNTQwfjhzRnl3Z0xRSlZJTDhZeU1ibnhpRVFBQUFBJCQAAAAAAAAAAAEAAAAnQDHOyfq77rXDd2luZHkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIzhVGKM4VRiT2; H_PS_PSSID=36426_31660_35912_36167_34584_35979_36055_36235_26350; BA_HECTOR=ak20800k8kag8h8le71h8646s0q; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; PSINO=6&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用代理IP。</li>
<li>限制请求频率，避免被封IP。   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sleep_time = random.uniform(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">time.sleep(sleep_time)</span><br></pre></td></tr></table></figure></li>
<li>处理验证码和登录等复杂场景。</li>
</ul>
<h3 id="网络请求库："><a href="#网络请求库：" class="headerlink" title="网络请求库："></a><strong>网络请求库：</strong></h3><ul>
<li><code>requests</code>库：用于发送HTTP请求，获取网页内容。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># url_base = &#x27;http://leo/index.phtml?reportdate=&#123;year&#125;&amp;quarter=&#123;quarter&#125;&amp;p=&#123;page&#125;&#x27;</span></span><br><span class="line"><span class="comment"># url = url_base.format(year=iyear, quarter=iquarter, page=page)  # 替换url模板中的占位符</span></span><br><span class="line">response = requests.get(url=url, headers=self.headers)</span><br><span class="line">res = response.content.decode()  <span class="comment"># 获取服务器响应的内容，将其解码成字符串</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="HTML解析库："><a href="#HTML解析库：" class="headerlink" title="HTML解析库："></a><strong>HTML解析库：</strong></h3><ul>
<li><p><code>BeautifulSoup</code>：用于解析HTML文档，提取所需信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(res, <span class="string">&#x27;html.parser&#x27;</span>)           <span class="comment"># 解析 HTML 内容</span></span><br><span class="line">first_paragraph = soup.find(<span class="string">&#x27;p&#x27;</span>)                   <span class="comment"># 查找第一个&lt;p&gt;标签</span></span><br><span class="line">script = soup.find(<span class="built_in">id</span>=tag_id)                      <span class="comment"># 找到具有指定 id 属性的标签</span></span><br><span class="line"><span class="comment"># script.string.replace_with(new_string)           # 替换标签内容</span></span><br><span class="line"><span class="comment"># script.append(new_tag)                           # 在标签内追加新标签</span></span><br><span class="line"><span class="comment"># script.extract()                                 # 从文档中删除标签</span></span><br><span class="line">text = script.text                                 <span class="comment"># 获取标签内容   </span></span><br><span class="line"><span class="comment"># json_str = re.findall(r&#x27;\[.+\]&#x27;, text)[0]        # 用正则表达式 re 从 text 中查找一个或多个包含 JSON 数据的字符串的第一个匹配项</span></span><br><span class="line"><span class="comment"># data = json.loads(json_str)                      # 把json格式的字符串转换为Python类型</span></span><br><span class="line">script1 = soup.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;paragraph&#x27;</span>)       <span class="comment"># 查找带有指定class的&lt;p&gt;标签</span></span><br><span class="line">script2 = soup.find(<span class="string">&#x27;a&#x27;</span>, href=<span class="string">&#x27;https://...&#x27;</span>)       <span class="comment"># 查找带有指定属性的&lt;a&gt;标签</span></span><br><span class="line">labels = soup.find_all(<span class="string">&#x27;a&#x27;</span>, attrs=&#123;<span class="string">&#x27;href&#x27;</span>: <span class="literal">True</span>&#125;)  <span class="comment"># 模糊搜索HTML代码中所有含href属性的&lt;a&gt;标签</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>lxml</code>：使用类似 XPath 的功能解析HTML文档。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> html</span><br><span class="line">tree = html.fromstring(html_doc)</span><br><span class="line">paragraphs = tree.xpath(<span class="string">&#x27;//p&#x27;</span>)                                 <span class="comment"># 使用 XPath 表达式查找&lt;p&gt;标签</span></span><br><span class="line">paragraphs_with_class = tree.xpath(<span class="string">&#x27;//p[@class=&quot;paragraph&quot;]&#x27;</span>)  <span class="comment"># 使用 XPath 表达式查找具有指定class属性值的&lt;p&gt;标签</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据存储："><a href="#数据存储：" class="headerlink" title="数据存储："></a><strong>数据存储：</strong></h3><ul>
<li>文件存储：将爬取的数据保存为文本文件、CSV文件等。</li>
<li>数据库：使用SQLite、MySQL、MongoDB等数据库存储数据。   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">self, path</span>):</span><br><span class="line">   <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:   <span class="comment"># 加载存储在JSON文件中的数据, 指定文件为UTF-8编码</span></span><br><span class="line">       data = json.load(fp)</span><br><span class="line">   <span class="keyword">return</span> data</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, data, path</span>):</span><br><span class="line">   <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:   <span class="comment"># 以json格式保存, 最近一日各国疫情数据</span></span><br><span class="line">       json.dump(data, fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">baidu_search</span>(<span class="params">v_result_file</span>):   <span class="comment"># 保存csv数据</span></span><br><span class="line">   df = pd.DataFrame(</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="string">&#x27;关键字&#x27;</span>: kw_list, <span class="string">&#x27;页码&#x27;</span>: page_list, <span class="string">&#x27;标题&#x27;</span>: title_list,  <span class="string">&#x27;百度链接&#x27;</span>: href_list, </span><br><span class="line">         <span class="string">&#x27;真实链接&#x27;</span>: real_url_list, <span class="string">&#x27;更新时间&#x27;</span>: time_list, <span class="string">&#x27;简介&#x27;</span>: desc_list,</span><br><span class="line">         <span class="string">&#x27;网站名称&#x27;</span>: site_list,</span><br><span class="line">      &#125;</span><br><span class="line">   )</span><br><span class="line">   <span class="keyword">if</span> os.path.exists(v_result_file):</span><br><span class="line">         header = <span class="literal">None</span>   <span class="comment"># 已存在的csv文件保存时不用加标头</span></span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">         <span class="comment"># 创建新文件时，设置csv文件标头</span></span><br><span class="line">         header = [<span class="string">&#x27;关键词&#x27;</span>, <span class="string">&#x27;页码&#x27;</span>, <span class="string">&#x27;标题&#x27;</span>, <span class="string">&#x27;百度链接&#x27;</span>, <span class="string">&#x27;真实链接&#x27;</span>, <span class="string">&#x27;更新时间&#x27;</span>, <span class="string">&#x27;简介&#x27;</span>, <span class="string">&#x27;网站名称&#x27;</span>] </span><br><span class="line">   df.to_csv(v_result_file, mode=<span class="string">&#x27;a+&#x27;</span>, index=<span class="literal">False</span>, header=header, encoding=<span class="string">&#x27;utf_8_sig&#x27;</span>)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;结果保存成功:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(v_result_file))</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="爬虫框架"><a href="#爬虫框架" class="headerlink" title="爬虫框架"></a><strong>爬虫框架</strong></h3><ul>
<li>Scrapy：一个强大的Python爬虫框架，提供了高级功能如异步处理、中间件等。   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject myproject</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="动态网页爬取"><a href="#动态网页爬取" class="headerlink" title="动态网页爬取"></a><strong>动态网页爬取</strong></h3><ul>
<li>使用Selenium或Headless浏览器模拟浏览器行为。</li>
<li>处理JavaScript渲染的页面。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/09/02/Python%E7%88%AC%E8%99%AB/" data-id="clr3c3rdc000jw0v5174zghzj" data-title="Python spider" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/04/01/hexo-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          hexo | Hello World
        
      </div>
    </a>
  
  
    <a href="/2022/09/01/Python%E5%9F%BA%E7%A1%80/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Python 基础</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2046/12/">December 2046</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2046/12/30/nice-photo/">Nice Photo</a>
          </li>
        
          <li>
            <a href="/2024/01/07/SpringCloud/">SpringCloud</a>
          </li>
        
          <li>
            <a href="/2023/10/11/%E9%9D%A2%E8%AF%95/">面 逝</a>
          </li>
        
          <li>
            <a href="/2023/10/10/%E6%8A%80%E8%83%BD/">寄 能</a>
          </li>
        
          <li>
            <a href="/2023/07/31/Colab/">Colab</a>
          </li>
        
          <li>
            <a href="/2023/07/14/Pytorch/">Pytorch</a>
          </li>
        
          <li>
            <a href="/2023/07/10/Anaconda/">Anaconda</a>
          </li>
        
          <li>
            <a href="/2023/04/14/Docker/">Docker</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 fengcai<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>